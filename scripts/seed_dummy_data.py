"""Seed massive dummy data for AutoGlean system."""

import sys
import random
from pathlib import Path
from datetime import datetime, timedelta

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from autoglean.db.base import SessionLocal, Base, engine
from autoglean.db.models import (
    GeneralManagement, Department, User, Extractor, ExtractorShare,
    UserFavorite, ExtractorHistory, ExtractionJob, ExtractorUsageStats,
    ExtractorRating, VisibilityEnum
)
from autoglean.auth.security import get_password_hash


# Saudi Arabic names with English transliterations
FIRST_NAMES_AR = [
    "Ù…Ø­Ù…Ø¯", "Ø£Ø­Ù…Ø¯", "Ø¹Ø¨Ø¯Ø§Ù„Ù„Ù‡", "Ø¹Ø¨Ø¯Ø§Ù„Ø±Ø­Ù…Ù†", "ÙÙ‡Ø¯", "Ø®Ø§Ù„Ø¯", "Ø³Ù„Ø·Ø§Ù†", "Ø³Ø¹Ø¯", "Ø¹Ø¨Ø¯Ø§Ù„Ø¹Ø²ÙŠØ²",
    "ÙÙŠØµÙ„", "ØªØ±ÙƒÙŠ", "Ù…Ø´Ø¹Ù„", "Ø¨Ù†Ø¯Ø±", "Ù†Ø§ØµØ±", "Ø³Ø¹ÙˆØ¯", "Ø±Ø§Ø´Ø¯", "Ø·Ù„Ø§Ù„", "ÙˆÙ„ÙŠØ¯",
    "ÙØ§Ø·Ù…Ø©", "Ù†ÙˆØ±Ø©", "Ù…Ù†Ù‰", "Ø³Ø§Ø±Ø©", "Ø¹Ø§Ø¦Ø´Ø©", "Ù…Ø±ÙŠÙ…", "Ù‡Ù†Ø¯", "Ø±ÙŠÙ…", "Ø£Ù…Ù„", "Ù„Ø·ÙŠÙØ©",
    "Ø£ÙŠÙˆØ¨"  # Special user
]

FIRST_NAMES_EN = [
    "Mohammed", "Ahmed", "Abdullah", "Abdulrahman", "Fahad", "Khaled", "Sultan", "Saad", "Abdulaziz",
    "Faisal", "Turki", "Mishaal", "Bandar", "Nasser", "Saud", "Rashed", "Talal", "Waleed",
    "Fatima", "Noura", "Mona", "Sarah", "Aisha", "Mariam", "Hind", "Reem", "Amal", "Latifa",
    "Ayoub"  # Special user
]

LAST_NAMES_AR = [
    "Ø§Ù„Ø¹ØªÙŠØ¨ÙŠ", "Ø§Ù„Ø¯ÙˆØ³Ø±ÙŠ", "Ø§Ù„Ù‚Ø­Ø·Ø§Ù†ÙŠ", "Ø§Ù„ØºØ§Ù…Ø¯ÙŠ", "Ø§Ù„Ø²Ù‡Ø±Ø§Ù†ÙŠ", "Ø§Ù„Ø´Ù…Ø±ÙŠ", "Ø§Ù„Ù…Ø·ÙŠØ±ÙŠ",
    "Ø§Ù„Ø¹Ù…Ø±ÙŠ", "Ø§Ù„Ø­Ø±Ø¨ÙŠ", "Ø§Ù„Ø´Ù‡Ø±ÙŠ", "Ø§Ù„Ø¹Ù†Ø²ÙŠ", "Ø§Ù„Ø³Ù‡Ù„ÙŠ", "Ø§Ù„Ø¨Ù‚Ù…ÙŠ", "Ø§Ù„Ø³Ø¨ÙŠØ¹ÙŠ",
    "Ø§Ù„Ø®Ø§Ù„Ø¯ÙŠ", "Ø§Ù„Ø¬Ù‡Ù†ÙŠ", "Ø§Ù„Ù…Ø§Ù„ÙƒÙŠ", "Ø§Ù„Ø¹Ø³ÙŠØ±ÙŠ", "Ø§Ù„Ø±Ø´ÙŠØ¯ÙŠ", "Ø§Ù„Ø£Ø­Ù…Ø¯ÙŠ",
    "Ø§Ù„Ø²Ø§Ø­Ù…"  # Special user
]

LAST_NAMES_EN = [
    "Al-Otaibi", "Al-Dosari", "Al-Qahtani", "Al-Ghamdi", "Al-Zahrani", "Al-Shammari", "Al-Mutairi",
    "Al-Omari", "Al-Harbi", "Al-Shahri", "Al-Anzi", "Al-Sahli", "Al-Buqami", "Al-Subaie",
    "Al-Khalidi", "Al-Juhani", "Al-Maliki", "Al-Aseeri", "Al-Rashidi", "Al-Ahmadi",
    "Alzahim"  # Special user
]

# Extractor templates by department (name_ar, name_en, icon, desc_ar, desc_en, prompt)
EXTRACTORS_BY_DEPT = {
    "Emerging Technologies": [
        ("Ù…Ø³ØªØ®Ø±Ø¬ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ", "AI Analysis Extractor", "ğŸ¤–", "ØªØ­Ù„ÙŠÙ„ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "Analyze AI models and extract data", "Ù‚Ù… Ø¨ØªØ­Ù„ÙŠÙ„ Ù‡Ø°Ø§ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆØ§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©"),
        ("Ù…Ø¯Ù‚Ù‚ Ø¹Ù‚ÙˆØ¯ Ø§Ù„Ø¨Ù„ÙˆÙƒØ´ÙŠÙ†", "Blockchain Contract Auditor", "â›“ï¸", "Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø¹Ù‚ÙˆØ¯ Ø§Ù„Ø¨Ù„ÙˆÙƒØ´ÙŠÙ†", "Verify blockchain smart contracts", "ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ù‡Ø°Ø§ Ø§Ù„Ø¹Ù‚Ø¯ Ø§Ù„Ø°ÙƒÙŠ"),
        ("Ù…Ø­Ù„Ù„ Ø¨ÙŠØ§Ù†Ø§Øª IoT", "IoT Data Analyzer", "ğŸ“¡", "ØªØ­Ù„ÙŠÙ„ Ø¨ÙŠØ§Ù†Ø§Øª Ø¥Ù†ØªØ±Ù†Øª Ø§Ù„Ø£Ø´ÙŠØ§Ø¡", "Analyze Internet of Things data", "Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù‚Ø±Ø§Ø¡Ø§Øª Ù…Ù† Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø¬Ù‡Ø²Ø©"),
        ("Ù…Ø³ØªØ®Ø±Ø¬ Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„ØªØ¹Ù„Ù… Ø§Ù„Ø¢Ù„ÙŠ", "ML Model Extractor", "ğŸ§ ", "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù†Ù…Ø§Ø°Ø¬ ML", "Extract ML model information", "Ø§Ø³ØªØ®Ø±Ø¬ Ù…Ø¹Ù…Ø§Ø±ÙŠØ© Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ ÙˆÙ…Ø¹Ø§ÙŠÙŠØ±Ù‡"),
        ("Ù…Ø¯Ù‚Ù‚ ØµØ­Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¶Ø®Ù…Ø©", "Big Data Validator", "ğŸ’¾", "Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¶Ø®Ù…Ø©", "Validate big data quality", "ØªØ­Ù‚Ù‚ Ù…Ù† Ø³Ù„Ø§Ù…Ø© Ù…Ø¬Ù…ÙˆØ¹Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"),
    ],
    "E-Services": [
        ("Ù…Ø³ØªØ®Ø±Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ©", "E-Service Data Extractor", "ğŸŒ", "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ©", "Extract electronic request data", "Ø§Ø³ØªØ®Ø±Ø¬ ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ø·Ù„Ø¨"),
        ("Ù…Ø­Ù‚Ù‚ ØµØ­Ø© Ø§Ù„Ø·Ù„Ø¨Ø§Øª", "Request Validator", "âœ…", "Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ù‚Ø¯Ù…Ø©", "Validate submitted requests", "ØªØ­Ù‚Ù‚ Ù…Ù† Ø§ÙƒØªÙ…Ø§Ù„ Ù‡Ø°Ø§ Ø§Ù„Ø·Ù„Ø¨"),
        ("Ù…Ø³ØªØ®Ø±Ø¬ ØªÙ‚ÙŠÙŠÙ… Ø±Ø¶Ø§ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…", "User Satisfaction Extractor", "â­", "Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙ‚ÙŠÙŠÙ…Ø§Øª Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡", "Extract customer ratings", "Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„ØªÙ‚ÙŠÙŠÙ… ÙˆØ§Ù„ØªØ¹Ù„ÙŠÙ‚Ø§Øª"),
        ("Ù…Ø¯Ù‚Ù‚ Ù‡ÙˆÙŠØ© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…", "Identity Verifier", "ğŸ”", "Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ù‡ÙˆÙŠØ©", "Verify identity documents", "ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù‡ÙˆÙŠØ© Ø§Ù„ÙˆØ·Ù†ÙŠØ©"),
        ("Ù…Ø­Ù„Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø®Ø¯Ù…Ø§Øª", "Service Usage Analyzer", "ğŸ“Š", "ØªØ­Ù„ÙŠÙ„ Ø£Ù†Ù…Ø§Ø· Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø®Ø¯Ù…Ø§Øª", "Analyze service usage patterns", "Ø§Ø³ØªØ®Ø±Ø¬ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…"),
    ],
    "Data Management Office": [
        ("Ù…Ø³ØªØ®Ø±Ø¬ Ø¬ÙˆØ¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "Data Quality Extractor", "ğŸ¯", "ØªÙ‚ÙŠÙŠÙ… Ø¬ÙˆØ¯Ø© Ù…Ø¬Ù…ÙˆØ¹Ø§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "Assess dataset quality", "Ù‚ÙŠÙ‘Ù… Ø¬ÙˆØ¯Ø© Ù‡Ø°Ù‡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"),
        ("Ù…Ø­Ù„Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ©", "Metadata Analyzer", "ğŸ“‹", "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ©", "Extract metadata", "Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ÙˆØµÙÙŠØ© Ù…Ù† Ø§Ù„Ù…Ø³ØªÙ†Ø¯"),
        ("Ù…Ø¯Ù‚Ù‚ Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ù„Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "Data Compliance Auditor", "âš–ï¸", "Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù…ØªØ«Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "Verify data compliance", "ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù…ØªØ«Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ø³ÙŠØ§Ø³Ø§Øª"),
        ("Ù…Ø³ØªØ®Ø±Ø¬ ØªØµÙ†ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "Data Classification Extractor", "ğŸ·ï¸", "ØªØµÙ†ÙŠÙ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹", "Auto-classify data", "ØµÙ†Ù‘Ù Ù‡Ø°Ù‡ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø­Ø³Ø§Ø³ÙŠØ©"),
        ("Ù…Ø­Ù„Ù„ Ø³Ù„Ø§Ù„Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "Data Lineage Analyzer", "ğŸ”", "ØªØªØ¨Ø¹ Ø£ØµÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "Track data origin", "Ø§Ø³ØªØ®Ø±Ø¬ Ù…ØµØ¯Ø± ÙˆØªØ§Ø±ÙŠØ® Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"),
    ],
    "Database": [
        ("Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ø®Ø·Ø·Ø§Øª Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "Database Schema Extractor", "ğŸ—„ï¸", "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø®Ø·Ø·Ø§Øª SQL", "Extract SQL schemas", "Ø§Ø³ØªØ®Ø±Ø¬ Ù…Ø®Ø·Ø· Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"),
        ("Ù…Ø­Ù„Ù„ Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª SQL", "SQL Query Analyzer", "ğŸ’»", "ØªØ­Ù„ÙŠÙ„ ÙˆØªØ­Ø³ÙŠÙ† Ø§Ø³ØªØ¹Ù„Ø§Ù…Ø§Øª SQL", "Analyze and optimize SQL queries", "Ø­Ù„Ù„ Ù‡Ø°Ø§ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… ÙˆØ§Ù‚ØªØ±Ø­ ØªØ­Ø³ÙŠÙ†Ø§Øª"),
        ("Ù…Ø¯Ù‚Ù‚ Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ", "Backup Validator", "ğŸ’¾", "Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø³Ù„Ø§Ù…Ø© Ø§Ù„Ù†Ø³Ø® Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©", "Validate backup integrity", "ØªØ­Ù‚Ù‚ Ù…Ù† Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©"),
        ("Ù…Ø³ØªØ®Ø±Ø¬ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡", "Performance Data Extractor", "âš¡", "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ù‚Ø§ÙŠÙŠØ³ Ø£Ø¯Ø§Ø¡ Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "Extract database performance metrics", "Ø§Ø³ØªØ®Ø±Ø¬ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡"),
        ("Ù…Ø­Ù„Ù„ Ø§Ù„ÙÙ‡Ø§Ø±Ø³", "Index Analyzer", "ğŸ“‡", "ØªØ­Ù„ÙŠÙ„ ÙƒÙØ§Ø¡Ø© Ø§Ù„ÙÙ‡Ø§Ø±Ø³", "Analyze index efficiency", "Ø­Ù„Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„ÙÙ‡Ø§Ø±Ø³"),
    ],
    "VM": [
        ("Ù…Ø³ØªØ®Ø±Ø¬ Ø­Ø§Ù„Ø© Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©", "VM Status Extractor", "ğŸ–¥ï¸", "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø­Ø§Ù„Ø© VMs", "Extract VM status", "Ø§Ø³ØªØ®Ø±Ø¬ Ø­Ø§Ù„Ø© ÙˆÙ…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø¢Ù„Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©"),
        ("Ù…Ø­Ù„Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø±Ø¯", "Resource Usage Analyzer", "ğŸ“ˆ", "ØªØ­Ù„ÙŠÙ„ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙˆØ§Ø±Ø¯ VM", "Analyze VM resource usage", "Ø­Ù„Ù„ Ø§Ø³ØªØ®Ø¯Ø§Ù… CPU ÙˆØ§Ù„Ø°Ø§ÙƒØ±Ø©"),
        ("Ù…Ø¯Ù‚Ù‚ Ø§Ù„ØªÙƒÙˆÙŠÙ†", "Configuration Auditor", "âš™ï¸", "Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª VM", "Verify VM settings", "ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„ØªÙƒÙˆÙŠÙ†"),
        ("Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø³Ø¬Ù„Ø§Øª", "Log Extractor", "ğŸ“", "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ø£Ø­Ø¯Ø§Ø«", "Extract event logs", "Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ù…Ù‡Ù…Ø© Ù…Ù† Ø§Ù„Ø³Ø¬Ù„Ø§Øª"),
        ("Ù…Ø­Ù„Ù„ Ø§Ù„Ø£Ù…Ø§Ù†", "Security Analyzer", "ğŸ›¡ï¸", "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø«ØºØ±Ø§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ©", "Analyze security vulnerabilities", "Ø§ÙØ­Øµ VM Ø¨Ø­Ø«Ø§Ù‹ Ø¹Ù† Ø«ØºØ±Ø§Øª"),
    ],
    "OS": [
        ("Ù…Ø³ØªØ®Ø±Ø¬ Ø³Ø¬Ù„Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…", "System Log Extractor", "ğŸ“„", "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø³Ø¬Ù„Ø§Øª Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ´ØºÙŠÙ„", "Extract OS logs", "Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø£Ø­Ø¯Ø§Ø« Ø§Ù„Ø­Ø±Ø¬Ø©"),
        ("Ù…Ø­Ù„Ù„ ØªØµØ­ÙŠØ­Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù†", "Security Patch Analyzer", "ğŸ”’", "ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ©", "Analyze security updates", "Ø­Ù„Ù„ Ø­Ø§Ù„Ø© Ø§Ù„ØªØµØ­ÙŠØ­Ø§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ©"),
        ("Ù…Ø¯Ù‚Ù‚ Ø§Ù„ØªØ±Ø§Ø®ÙŠØµ", "License Auditor", "ğŸ“œ", "Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØªØ±Ø§Ø®ÙŠØµ Ø§Ù„Ø¨Ø±Ø§Ù…Ø¬", "Verify software licenses", "ØªØ­Ù‚Ù‚ Ù…Ù† ØµÙ„Ø§Ø­ÙŠØ© Ø§Ù„ØªØ±Ø®ÙŠØµ"),
        ("Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…", "System Info Extractor", "â„¹ï¸", "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…", "Extract system information", "Ø§Ø³ØªØ®Ø±Ø¬ Ù†Ø³Ø®Ø© ÙˆØ¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…"),
        ("Ù…Ø­Ù„Ù„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª", "Process Analyzer", "âš™ï¸", "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ù‚ÙŠØ¯ Ø§Ù„ØªØ´ØºÙŠÙ„", "Analyze running processes", "Ø­Ù„Ù„ Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ù…ÙˆØ§Ø±Ø¯ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª"),
    ],
    "Risk Management": [
        ("Ù…Ø¯Ù‚Ù‚ ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø®Ø§Ø·Ø±", "Risk Assessment Auditor", "âš ï¸", "ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ø£Ù…Ù†ÙŠØ©", "Assess security risks", "Ù‚ÙŠÙ‘Ù… Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ù…Ø®Ø§Ø·Ø± ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ†Ø¯"),
        ("Ù…Ø³ØªØ®Ø±Ø¬ ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„", "Compliance Report Extractor", "ğŸ“Š", "Ø§Ø³ØªØ®Ø±Ø§Ø¬ ØªÙ‚Ø§Ø±ÙŠØ± Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„", "Extract compliance reports", "Ø§Ø³ØªØ®Ø±Ø¬ Ù†ØªØ§Ø¦Ø¬ Ø§Ù„ØªØ¯Ù‚ÙŠÙ‚"),
        ("Ù…Ø­Ù„Ù„ Ø§Ù„Ø«ØºØ±Ø§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ©", "Vulnerability Analyzer", "ğŸ”“", "ØªØ­Ù„ÙŠÙ„ Ù†Ù‚Ø§Ø· Ø§Ù„Ø¶Ø¹Ù", "Analyze security weaknesses", "Ø­Ø¯Ø¯ Ø§Ù„Ø«ØºØ±Ø§Øª Ø§Ù„Ø£Ù…Ù†ÙŠØ©"),
        ("Ù…Ø³ØªØ®Ø±Ø¬ Ø®Ø·Ø· Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©", "Response Plan Extractor", "ğŸš¨", "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø®Ø·Ø· Ø§Ù„Ø·ÙˆØ§Ø±Ø¦", "Extract emergency plans", "Ø§Ø³ØªØ®Ø±Ø¬ Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©"),
        ("Ù…Ø¯Ù‚Ù‚ Ø§Ù„Ø³ÙŠØ§Ø³Ø§Øª", "Policy Auditor", "ğŸ“‹", "Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ù„Ù„Ø³ÙŠØ§Ø³Ø§Øª", "Verify policy compliance", "ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ØªØ²Ø§Ù… Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø¨Ø§Ù„Ø³ÙŠØ§Ø³Ø§Øª"),
    ],
    "IT Strategy & Planning": [
        ("Ù…Ø³ØªØ®Ø±Ø¬ Ø®Ø·Ø· Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹", "Project Plan Extractor", "ğŸ“…", "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…ÙƒÙˆÙ†Ø§Øª Ø®Ø·Ø· Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹", "Extract project plan components", "Ø§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù…Ù‡Ø§Ù… ÙˆØ§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ø²Ù…Ù†ÙŠØ©"),
        ("Ù…Ø­Ù„Ù„ Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ©", "Budget Analyzer", "ğŸ’°", "ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ§Øª", "Analyze budgets", "Ø­Ù„Ù„ Ø¨Ù†ÙˆØ¯ Ø§Ù„Ù…ÙŠØ²Ø§Ù†ÙŠØ© ÙˆØ§Ù„ØªÙƒØ§Ù„ÙŠÙ"),
        ("Ù…Ø¯Ù‚Ù‚ Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡", "KPI Auditor", "ğŸ“Š", "Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† KPIs", "Verify KPIs", "Ø§Ø³ØªØ®Ø±Ø¬ ÙˆÙ‚ÙŠÙ‘Ù… Ù…Ø¤Ø´Ø±Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡"),
        ("Ù…Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©", "Strategic Goal Extractor", "ğŸ¯", "Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù", "Extract strategic goals", "Ø­Ø¯Ø¯ Ø§Ù„Ø£Ù‡Ø¯Ø§Ù Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ©"),
        ("Ù…Ø­Ù„Ù„ ROI", "ROI Analyzer", "ğŸ’¹", "ØªØ­Ù„ÙŠÙ„ Ø¹Ø§Ø¦Ø¯ Ø§Ù„Ø§Ø³ØªØ«Ù…Ø§Ø±", "Analyze return on investment", "Ø§Ø­Ø³Ø¨ Ø¹Ø§Ø¦Ø¯ Ø§Ù„Ø§Ø³ØªØ«Ù…Ø§Ø± Ø§Ù„Ù…ØªÙˆÙ‚Ø¹"),
    ],
}


def generate_email(first_name, last_name):
    """Generate email from name."""
    # Transliterate Arabic names to Latin for email
    email_name = f"{first_name[0].lower()}{last_name.lower()}"
    # Remove Arabic characters and use placeholder
    import re
    email_name = re.sub(r'[^\x00-\x7F]+', '', email_name)
    if not email_name:
        email_name = f"user{random.randint(1000, 9999)}"
    return f"{email_name}@mewa.gov.sa"


def seed_data():
    """Seed comprehensive dummy data."""
    print("ğŸ—‘ï¸  Dropping all existing tables...")
    Base.metadata.drop_all(bind=engine)

    print("ğŸ—ï¸  Creating fresh tables...")
    Base.metadata.create_all(bind=engine)

    db = SessionLocal()

    try:
        # 1. Create General Managements
        print("\nğŸ“Š Creating General Managements...")
        gms = {
            "Digital Transformation": GeneralManagement(
                name_en="Digital Transformation",
                name_ar="Ø§Ù„ØªØ­ÙˆÙ„ Ø§Ù„Ø±Ù‚Ù…ÙŠ",
                description_en="General Management for Digital Transformation",
                description_ar="Ø§Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„ØªØ­ÙˆÙ„ Ø§Ù„Ø±Ù‚Ù…ÙŠ"
            ),
            "Infrastructure": GeneralManagement(
                name_en="Infrastructure",
                name_ar="Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØªØ­ØªÙŠØ©",
                description_en="General Management for Infrastructure",
                description_ar="Ø§Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØªØ­ØªÙŠØ©"
            ),
            "IT Governance": GeneralManagement(
                name_en="IT Governance",
                name_ar="Ø­ÙˆÙƒÙ…Ø© ØªÙ‚Ù†ÙŠØ© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª",
                description_en="General Management for IT Governance",
                description_ar="Ø§Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù„Ø­ÙˆÙƒÙ…Ø© ØªÙ‚Ù†ÙŠØ© Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª"
            ),
        }

        for gm in gms.values():
            db.add(gm)
        db.commit()
        print(f"âœ… Created {len(gms)} General Managements")

        # Refresh to get IDs
        for key in gms:
            db.refresh(gms[key])

        # 2. Create Departments
        print("\nğŸ¢ Creating Departments...")
        dept_structure = {
            "Digital Transformation": [
                ("Emerging Technologies", "Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù†Ø§Ø´Ø¦Ø©", "Emerging Technologies Department", "Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù†Ø§Ø´Ø¦Ø©"),
                ("E-Services", "Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ©", "E-Services Department", "Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø®Ø¯Ù…Ø§Øª Ø§Ù„Ø¥Ù„ÙƒØªØ±ÙˆÙ†ÙŠØ©"),
                ("Data Management Office", "Ù…ÙƒØªØ¨ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "Data Management Office", "Ù…ÙƒØªØ¨ Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"),
            ],
            "Infrastructure": [
                ("Database", "Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", "Database Administration", "Ø¥Ø¯Ø§Ø±Ø© Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"),
                ("VM", "Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©", "Virtual Machines Administration", "Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø£Ø¬Ù‡Ø²Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©"),
                ("OS", "Ø£Ù†Ø¸Ù…Ø© Ø§Ù„ØªØ´ØºÙŠÙ„", "Operating Systems Administration", "Ø¥Ø¯Ø§Ø±Ø© Ø£Ù†Ø¸Ù…Ø© Ø§Ù„ØªØ´ØºÙŠÙ„"),
            ],
            "IT Governance": [
                ("Risk Management", "Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±", "Risk Management Department", "Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø®Ø§Ø·Ø±"),
                ("IT Strategy & Planning", "Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© ÙˆØ§Ù„ØªØ®Ø·ÙŠØ·", "IT Strategy & Planning Department", "Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© ÙˆØ§Ù„ØªØ®Ø·ÙŠØ·"),
            ],
        }

        departments = {}
        for gm_name, depts in dept_structure.items():
            for dept_name, name_ar, desc_en, desc_ar in depts:
                dept = Department(
                    name_en=dept_name,
                    name_ar=name_ar,
                    gm_id=gms[gm_name].id,
                    description_en=desc_en,
                    description_ar=desc_ar
                )
                db.add(dept)
                departments[dept_name] = dept

        db.commit()
        print(f"âœ… Created {len(departments)} Departments")

        # Refresh departments
        for dept in departments.values():
            db.refresh(dept)

        # 3. Create Users (3-5 per department, focusing on DT and Infra)
        print("\nğŸ‘¥ Creating Users...")
        users = []

        # Special user: Ayoub Alzahim
        special_user = User(
            full_name_en="Ayoub Alzahim",
            full_name_ar="Ø£ÙŠÙˆØ¨ Ø§Ù„Ø²Ø§Ø­Ù…",
            email="aalzahim@mewa.gov.sa",
            department_id=departments["Emerging Technologies"].id,
            password_hash=get_password_hash("aalzahim@mewa.gov.sa"),
            is_active=True
        )
        db.add(special_user)
        users.append(special_user)

        # Generate users for each department
        used_emails = {"aalzahim@mewa.gov.sa"}
        for dept_name, dept in departments.items():
            # More users for DT and Infra departments
            if dept_name in ["Emerging Technologies", "E-Services", "Data Management Office", "Database", "VM", "OS"]:
                num_users = random.randint(4, 5)
            else:
                num_users = random.randint(3, 4)

            for _ in range(num_users):
                idx_first = random.randint(0, len(FIRST_NAMES_AR) - 1)
                idx_last = random.randint(0, len(LAST_NAMES_AR) - 1)

                first_name_ar = FIRST_NAMES_AR[idx_first]
                last_name_ar = LAST_NAMES_AR[idx_last]
                first_name_en = FIRST_NAMES_EN[idx_first]
                last_name_en = LAST_NAMES_EN[idx_last]

                full_name_ar = f"{first_name_ar} {last_name_ar}"
                full_name_en = f"{first_name_en} {last_name_en}"

                # Generate unique email (using English name)
                attempt = 0
                while attempt < 10:
                    email = f"{first_name_en[0].lower()}{last_name_en.replace('-', '').lower()}{attempt if attempt > 0 else ''}@mewa.gov.sa"

                    if email not in used_emails:
                        used_emails.add(email)
                        break
                    attempt += 1

                user = User(
                    full_name_en=full_name_en,
                    full_name_ar=full_name_ar,
                    email=email,
                    department_id=dept.id,
                    password_hash=get_password_hash(email),
                    is_active=True
                )
                db.add(user)
                users.append(user)

        db.commit()
        print(f"âœ… Created {len(users)} Users")

        # Refresh users
        for user in users:
            db.refresh(user)

        # 4. Create Extractors (2-5 per user)
        print("\nğŸ”§ Creating Extractors...")
        extractors = []
        user_extractors = {}  # Track extractors by user
        extractor_counter = 1

        for user in users:
            dept = db.query(Department).filter(Department.id == user.department_id).first()
            dept_name = dept.name_en  # Use English name as key
            extractor_templates = EXTRACTORS_BY_DEPT.get(dept_name, [])

            if not extractor_templates:
                continue

            num_extractors = random.randint(2, min(5, len(extractor_templates)))
            selected_templates = random.sample(extractor_templates, num_extractors)

            user_extractors[user.id] = []
            for name_ar, name_en, icon, desc_ar, desc_en, prompt in selected_templates:
                visibility = random.choices(
                    [VisibilityEnum.PUBLIC, VisibilityEnum.PRIVATE, VisibilityEnum.SHARED],
                    weights=[0.4, 0.4, 0.2]
                )[0]

                extractor = Extractor(
                    extractor_id=f"ext-{extractor_counter:04d}",
                    name_en=name_en,
                    name_ar=name_ar,
                    icon=icon,
                    description_en=desc_en,
                    description_ar=desc_ar,
                    prompt=prompt,
                    llm=random.choice(["gemini-flash", "gemini-pro"]),
                    temperature=round(random.uniform(0.3, 0.9), 1),
                    max_tokens=random.choice([1000, 2000, 4000]),
                    visibility=visibility,
                    owner_id=user.id
                )
                db.add(extractor)
                extractors.append(extractor)
                user_extractors[user.id].append(extractor)
                extractor_counter += 1

        db.commit()
        print(f"âœ… Created {len(extractors)} Extractors")

        # Refresh extractors
        for extractor in extractors:
            db.refresh(extractor)

        # 5. Create Extraction Jobs (10-50 per user)
        print("\nğŸ“‹ Creating Extraction Jobs...")
        jobs = []
        job_counter = 1

        for user in users:
            if user.id not in user_extractors or not user_extractors[user.id]:
                continue

            num_jobs = random.randint(10, 50)
            for _ in range(num_jobs):
                extractor = random.choice(user_extractors[user.id])

                # Generate job
                days_ago = random.randint(0, 90)
                created_at = datetime.utcnow() - timedelta(days=days_ago)

                status = random.choices(
                    ["completed", "failed", "pending"],
                    weights=[0.85, 0.10, 0.05]
                )[0]

                completed_at = created_at + timedelta(minutes=random.randint(1, 30)) if status in ["completed", "failed"] else None

                filename = f"document_{random.randint(1000, 9999)}.pdf"
                job = ExtractionJob(
                    job_id=f"job-{job_counter:06d}",
                    user_id=user.id,
                    extractor_id=extractor.id,
                    file_name=filename,
                    file_path=f"/app/storage/documents/{f'job-{job_counter:06d}'}/{filename}",
                    status=status,
                    result_content="Ù†ØªÙŠØ¬Ø© Ø§Ù„Ø§Ø³ØªØ®Ø±Ø§Ø¬" if status == "completed" else None,
                    error_message="Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©" if status == "failed" else None,
                    created_at=created_at,
                    completed_at=completed_at
                )
                db.add(job)
                jobs.append(job)
                job_counter += 1

        db.commit()
        print(f"âœ… Created {len(jobs)} Extraction Jobs")

        # 6. Create Usage Stats (aggregated per extractor)
        print("\nğŸ“ˆ Creating Usage Stats...")
        stats_records = []

        for extractor in extractors:
            # Count all jobs for this extractor
            total_jobs = db.query(ExtractionJob).filter(
                ExtractionJob.extractor_id == extractor.id
            ).count()

            successful_jobs = db.query(ExtractionJob).filter(
                ExtractionJob.extractor_id == extractor.id,
                ExtractionJob.status == "completed"
            ).count()

            failed_jobs = db.query(ExtractionJob).filter(
                ExtractionJob.extractor_id == extractor.id,
                ExtractionJob.status == "failed"
            ).count()

            if total_jobs > 0:
                stat = ExtractorUsageStats(
                    extractor_id=extractor.id,
                    total_uses=total_jobs,
                    successful_uses=successful_jobs,
                    failed_uses=failed_jobs,
                    last_used_at=datetime.utcnow() - timedelta(days=random.randint(0, 30))
                )
                db.add(stat)
                stats_records.append(stat)

        db.commit()
        print(f"âœ… Created {len(stats_records)} Usage Stats")

        # 7. Create Ratings (ensure leaderboard thresholds)
        print("\nâ­ Creating Ratings...")
        ratings = []

        # For each extractor, create ratings from different users
        for extractor in extractors:
            # 60% of extractors get ratings
            if random.random() < 0.6:
                num_ratings = random.randint(3, 12)  # Ensure >= 3 for leaderboard

                # Get random users who didn't create this extractor
                potential_raters = [u for u in users if u.id != extractor.owner_id]
                raters = random.sample(potential_raters, min(num_ratings, len(potential_raters)))

                for rater in raters:
                    rating_value = random.choices(
                        [1, 2, 3, 4, 5],
                        weights=[0.05, 0.10, 0.20, 0.35, 0.30]  # Skewed toward higher ratings
                    )[0]

                    reviews = [
                        "Ù…Ø³ØªØ®Ø±Ø¬ Ù…Ù…ØªØ§Ø² ÙˆØ¯Ù‚ÙŠÙ‚",
                        "Ù…ÙÙŠØ¯ Ø¬Ø¯Ø§Ù‹",
                        "ÙŠØ­ØªØ§Ø¬ ØªØ­Ø³ÙŠÙ†",
                        "Ù†ØªØ§Ø¦Ø¬ Ø±Ø§Ø¦Ø¹Ø©",
                        "Ø³Ø±ÙŠØ¹ ÙˆÙ…ÙˆØ«ÙˆÙ‚",
                        "Ù…Ù†Ø§Ø³Ø¨ Ù„Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù…",
                    ]

                    rating = ExtractorRating(
                        extractor_id=extractor.id,
                        user_id=rater.id,
                        rating=rating_value,
                        review=random.choice(reviews) if random.random() < 0.7 else None,
                        created_at=datetime.utcnow() - timedelta(days=random.randint(0, 60))
                    )
                    db.add(rating)
                    ratings.append(rating)

        db.commit()
        print(f"âœ… Created {len(ratings)} Ratings")

        # 8. Create Shares (for SHARED extractors)
        print("\nğŸ”— Creating Extractor Shares...")
        shares = []

        shared_extractors = [e for e in extractors if e.visibility == VisibilityEnum.SHARED]
        for extractor in shared_extractors:
            # Share with 1-3 users
            num_shares = random.randint(1, 3)
            potential_users = [u for u in users if u.id != extractor.owner_id]
            shared_with = random.sample(potential_users, min(num_shares, len(potential_users)))

            for user in shared_with:
                share = ExtractorShare(
                    extractor_id=extractor.id,
                    user_id=user.id
                )
                db.add(share)
                shares.append(share)

        db.commit()
        print(f"âœ… Created {len(shares)} Shares")

        # 9. Create Favorites
        print("\nâ¤ï¸  Creating Favorites...")
        favorites = []

        for user in users:
            # Each user favorites 2-8 public extractors
            public_extractors = [e for e in extractors if e.visibility == VisibilityEnum.PUBLIC and e.owner_id != user.id]
            if public_extractors:
                num_favorites = random.randint(2, min(8, len(public_extractors)))
                favorited = random.sample(public_extractors, num_favorites)

                for extractor in favorited:
                    favorite = UserFavorite(
                        user_id=user.id,
                        extractor_id=extractor.id
                    )
                    db.add(favorite)
                    favorites.append(favorite)

        db.commit()
        print(f"âœ… Created {len(favorites)} Favorites")

        # Print Summary
        print("\n" + "="*60)
        print("âœ… DUMMY DATA SEEDING COMPLETED!")
        print("="*60)
        print(f"ğŸ“Š General Managements: {len(gms)}")
        print(f"ğŸ¢ Departments: {len(departments)}")
        print(f"ğŸ‘¥ Users: {len(users)}")
        print(f"ğŸ”§ Extractors: {len(extractors)}")
        print(f"ğŸ“‹ Extraction Jobs: {len(jobs)}")
        print(f"ğŸ“ˆ Usage Stats: {len(stats_records)}")
        print(f"â­ Ratings: {len(ratings)}")
        print(f"ğŸ”— Shares: {len(shares)}")
        print(f"â¤ï¸  Favorites: {len(favorites)}")
        print("="*60)

        print("\nğŸ”‘ Special Account:")
        print(f"   Name: Ø£ÙŠÙˆØ¨ Ø§Ù„Ø²Ø§Ø­Ù…")
        print(f"   Email: aalzahim@mewa.gov.sa")
        print(f"   Password: aalzahim@mewa.gov.sa")
        print(f"   Department: Emerging Technologies")
        print("="*60)

    except Exception as e:
        print(f"\nâŒ Error seeding data: {e}")
        import traceback
        traceback.print_exc()
        db.rollback()
        raise
    finally:
        db.close()


if __name__ == "__main__":
    seed_data()
